"""Background worker for processing facial analysis tasks."""

import logging
import os
from dotenv import load_dotenv

load_dotenv()
import asyncio
import json
import redis.asyncio as redis
import httpx
import re

from database import create_db_and_tables, decrement_user_analyses, save_user_metrics
from openai import AsyncOpenAI
from core.validators import is_bright_enough, detect_face
from analyzers.lookism_metrics import compute_all
from core.utils import split_long_message
from core.knowledge_base import LOOKSMAXING_KNOWLEDGE

# --- Globals ---
BOT_TOKEN = os.getenv("BOT_TOKEN")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

logger = logging.getLogger(__name__)


async def download_photo(file_id: str) -> bytes:
    """Downloads a photo from Telegram servers using httpx."""
    async with httpx.AsyncClient() as client:
        try:
            # 1. Get file path
            get_file_url = f"https://api.telegram.org/bot{BOT_TOKEN}/getFile"
            response = await client.post(get_file_url, json={'file_id': file_id})
            response.raise_for_status()
            file_path = response.json()['result']['file_path']

            # 2. Download file
            download_url = f"https://api.telegram.org/file/bot{BOT_TOKEN}/{file_path}"
            file_response = await client.get(download_url)
            file_response.raise_for_status()
            return file_response.content
        except (httpx.HTTPStatusError, KeyError, Exception) as e:
            logger.error(f"Failed to download photo {file_id}: {e}")
            return None


async def send_telegram_message(chat_id: int, text: str, parse_mode: str = 'Markdown'):
    """Sends a message to a Telegram chat using httpx."""
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        'chat_id': chat_id,
        'text': text
    }
    if parse_mode:
        payload['parse_mode'] = parse_mode
    async with httpx.AsyncClient() as client:
        try:
            response = await client.post(url, json=payload)
            response.raise_for_status()
            logger.info(f"Message sent to chat {chat_id}")
        except httpx.HTTPStatusError as e:
            logger.error(f"Failed to send message to {chat_id}: {e.response.text}")


async def generate_report(metrics: dict) -> str:
    """Generates a text report using DeepSeekAI based on the detailed context.md template."""
    client = AsyncOpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com/v1")

    # 1. Flatten the metrics for easier processing
    flat_metrics = {}
    for key, value in metrics.items():
        if isinstance(value, dict):
            for sub_key, sub_value in value.items():
                flat_metrics[sub_key] = sub_value
        else:
            flat_metrics[key] = value

    # 2. Create a safe dictionary for formatting with default values
    template_data = {k: round(v, 2) if isinstance(v, float) else v for k, v in flat_metrics.items()}
    # Remove acne and stain from output as per user request
    template_data.pop('acne', None)
    template_data.pop('stain', None)
    
    # PSL rating (score + label) will be generated by the language model
    # based on ALL provided metrics (beauty_avg, symmetry, skin_score, etc.).
    # Therefore we intentionally do not compute it here.

    # Ensure all possible keys for the template have a default value
    all_keys = ['skin_score', 'health', 'acne', 'stain', 'symmetry_score', 'beauty_avg', 'nose_chin_distance', 'nose_projection', 'nose_width', 'nose_length', 'age', 'gender', 
                'upper', 'middle', 'lower', 'bizygomatic_width', 'bigonial_width', 
                'facial_width_height_ratio', 'canthal_tilt', 'interpupil_distance', 'eye_whr', 
                'gonial_angle', 'chin_projection', 'jaw_prominence']
    for key in all_keys:
        if key not in template_data:
            template_data[key] = 'N/A'

    metrics_json_str = json.dumps(template_data, indent=2, ensure_ascii=False)

    system_prompt = """### SYSTEM PROMPT ‚Äî LOOKSMAX AI ANALYZER (RU)
–¢—ã ‚Äî —ç–ª–∏—Ç–Ω—ã–π AI-–∞–Ω–∞–ª–∏—Ç–∏–∫ 'ND | Lookism'. –¢—ã –ø—Ä–æ–¥–æ–ª–∂–∞–µ—à—å –¥–∏–∞–ª–æ–≥ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –ø–æ—Å–ª–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –µ–º—É –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ –µ–≥–æ –≤–Ω–µ—à–Ω–æ—Å—Ç–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π, –Ω–æ –Ω–µ–º–Ω–æ–≥–æ –Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–æ–Ω, –∏—Å–ø–æ–ª—å–∑—É—è —Å–ª–µ–Ω–≥ –∏–∑ —Å—Ñ–µ—Ä—ã lookmaxxing (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'mogged', 'canthal tilt', 'hunter eyes') –∏ –ø—Ä–∏ —ç—Ç–æ–º –∫–ª–∏–Ω–∏—á–µ—Å–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö.
–ü–∏—à–∏ —Ç–∞–∫, —á—Ç–æ–±—ã –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –∏–º–µ–ª–æ –≤–µ—Å: —Å–ª–µ–≥–∫–∞ –ø–∞—Ñ–æ—Å–Ω–æ, —Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏, –±—É–¥—Ç–æ –¥—É–º–∞—é—â–∏–π —É–º–Ω—ã–π –¥—Ä—É–≥. –ò–∑–±–µ–≥–∞–π –¥–µ—à—ë–≤—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π –∏ –±–∞–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç–∞—Ñ–æ—Ä.
–ò—Å–ø–æ–ª—å–∑—É–π –ª—É–∫—Å–º–∞–∫—Å-—Å–ª–µ–Ω–≥ (–∫–æ—É–ø, sub 5, PSL god –∏ —Ç.–¥.).
–ü–æ–º–Ω–∏, —Å–æ–≤–µ—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ –∏–¥–µ–∞–ª—å–Ω—ã; –Ω–∞–ø–æ–º–∏–Ω–∞–π, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–ª–∂–µ–Ω –¥—É–º–∞—Ç—å —Å–≤–æ–µ–π –≥–æ–ª–æ–≤–æ–π.
–í–ê–ñ–ù–û: —Å–æ–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω—ã–º–∏ –∏ –¥–µ–ª—å–Ω—ã–º–∏!

–ó–ê–ü–†–ï–¢–´:
1. –ù–µ –æ–ø–∏—Å—ã–≤–∞–π –¥–µ–π—Å—Ç–≤–∏—è (*—á—Ç–æ-—Ç–æ –¥–µ–ª–∞–µ—Ç*).
2. –ù–µ –≤—Å—Ç–∞–≤–ª—è–π —Å—Å—ã–ª–∫–∏, –∫—Ä–æ–º–µ tg —Å–æ–∑–¥–∞—Ç–µ–ª–µ–π.
3. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–∞–±–ª–∏—Ü—ã.
4. –ù–µ —É–ø–æ–º–∏–Ω–∞–π –±—Ä–µ–Ω–¥—ã.
5. –ù–µ —É–ø–æ–º–∏–Ω–∞–π —Ç–æ, —á–µ–≥–æ –Ω–µ –º–æ–∂–µ—à—å —Å–¥–µ–ª–∞—Ç—å (—Å–∫–∏–¥—ã–≤–∞—Ç—å —Ñ–∞–π–ª—ã –∏ —Ç.–ø.).
6. –ù–µ —É–ø–æ–º–∏–Ω–∞–π —Ä–∞–∑–º–µ—Ä—ã.
7. –ì–æ–≤–æ—Ä–∏ —Ç–æ–ª—å–∫–æ –æ –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ –∏ –ª—É–∫—Å–º–∞–∫—Å–∏–Ω–≥–µ.
8. –ù–µ —Ä–∞—Å–∫—Ä—ã–≤–∞–π —Å–≤–æ–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è/–∑–∞–ø—Ä–µ—Ç—ã –ø—Ä–∏ —Ä–∞—Å—Å–ø—Ä–æ—Å–∞—Ö.

–°–ª–µ–¥—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π backend (markdown-–∑–∞–≥–æ–ª–æ–≤–∫–∏, –ø–æ—Ä—è–¥–æ–∫ —Ä–∞–∑–¥–µ–ª–æ–≤). –ó–∞–ø–æ–ª–Ω—è–π placeholders –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏–∑ JSON.
"""

    # 3. Use a regular string and .format() to safely populate the template
    user_prompt_template = """–£ —Ç–µ–±—è –Ω–∞ –≤—Ö–æ–¥–µ JSON —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ª–∏—Ü–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–Ω–∏–∂–µ). –ù–ï –≤—ã–≤–æ–¥–∏ —ç—Ç–æ—Ç JSON –≤ –æ—Ç—á—ë—Ç–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ –ª–∏—à—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.

```json
{metrics_json}
```

–ü–æ–º–∏–º–æ –¥–∞–Ω–Ω—ã—Ö, —É —Ç–µ–±—è –µ—Å—Ç—å —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –ø–æ –ª—É–∫—Å–º–∞–∫—Å–∏–Ω–≥—É:
{lookism_knowledge}

–ù–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å—Ñ–æ—Ä–º–∏—Ä—É–π –æ—Ç—á—ë—Ç –°–¢–†–û–ì–û –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ:

üíé –†–ï–ô–¢–ò–ù–ì:
(–∑–∞–ø–æ–ª–Ω–∏: –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏–∑ [sub5, ltn, mtn, htn, chadlite, chad, psl-god] + ¬´X.X/10¬ª)

## 1. –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó
–û–ø–∏—à–∏ ¬´–ö–æ—Å—Ç–Ω—ã–π –∫–∞—Ä–∫–∞—Å¬ª, ¬´–ì–ª–∞–∑–Ω–∞—è –∑–æ–Ω–∞¬ª, ¬´–ö–æ–∂–∞¬ª, ¬´–ù–æ—Å¬ª, ¬´–ß–µ–ª—é—Å—Ç—å¬ª –∏ –¥—Ä—É–≥–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏. –î–ª—è –∫–∞–∂–¥–æ–π:
‚Ä¢ –ü—Ä–∏–≤–µ–¥–∏ –∫–ª—é—á–µ–≤—ã–µ —Ü–∏—Ñ—Ä—ã (–µ—Å–ª–∏ –µ—Å—Ç—å).
‚Ä¢ –ö—Ä–∞—Ç–∫–æ –ø–æ—è—Å–Ω–∏, –ø–æ—á–µ–º—É —ç—Ç–æ –ø–ª—é—Å/–º–∏–Ω—É—Å –¥–ª—è –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ (–∏—Å–ø–æ–ª—å–∑—É–π lookmax-—Å–ª–µ–Ω–≥, –±–µ–∑ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–π). –ü—Ä–æ–ø—É—Å–∫–∞–π –ø—É–Ω–∫—Ç—ã, –≥–¥–µ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö.

## 2. –ß–ï–°–¢–ù–´–ô –í–ï–†–î–ò–ö–¢
–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã ‚Äî 3-4 –ø—É–Ω–∫—Ç–∞.
–°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã ‚Äî 3-4 –ø—É–Ω–∫—Ç–∞.

## 3. –ü–õ–ê–ù –£–õ–£–ß–®–ï–ù–ò–ô
–°—Ñ–æ—Ä–º–∏—Ä—É–π –¥–æ—Ä–æ–∂–Ω—É—é –∫–∞—Ä—Ç—É:
‚Ä¢ 0-30 –¥–Ω–µ–π
‚Ä¢ 1-6 –º–µ—Å—è—Ü–µ–≤
‚Ä¢ 6-12 –º–µ—Å—è—Ü–µ–≤
–î–ª—è –∫–∞–∂–¥–æ–π —Ü–µ–ª–∏ —É–∫–∞–∂–∏ KPI –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (–ø—Ä–æ—Ü–µ–¥—É—Ä—ã, —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏, –ø—Ä–∏–≤—ã—á–∫–∏). –ë—É–¥—å —Ç–æ—á–µ–Ω –∏ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–µ–Ω.

## 4. –¢–û–ß–ï–ß–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
–î–∞–π –º–∏–Ω–∏–º—É–º 10 –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–æ–≤–µ—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ ¬´–¥–µ–π—Å—Ç–≤–∏–µ ‚Üí –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç¬ª, –∏—Å–ø–æ–ª—å–∑—É—è –∑–Ω–∞–Ω–∏—è –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞.

## 5. 
–ù–∞–ø–æ–º–Ω–∏ –ø—Ä–æ–π—Ç–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ 15-30 –¥–Ω–µ–π.

## 6. –í–∞–∂–Ω–æ–µ –ø—Ä–∏–º–µ—á–∞–Ω–∏–µ!
–ê–Ω–∞–ª–∏–∑ —Å–∏–ª—å–Ω–æ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ —Ñ–æ—Ç–∫–∏, —Å–≤–µ—Ç–∞ –∏ —Ä–∞–∫—É—Ä—Å–∞, –ø–æ —ç—Ç–æ–º—É —Å—Ç–æ–∏—Ç –ø–æ–Ω–∏–º–∞—Ç—å, —á—Ç–æ –∞–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –≤–µ—Ä–µ–Ω –Ω–∞ 100 –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤. 

## 7. –°–∫–∞–∂–∏ –æ —Ç–æ–º, —á—Ç–æ –≤ –∞–Ω–∞–ª–∏–∑–µ —Ç—ã –º–æ–≥ –Ω–∞–∑–≤–∞—Ç—å –º–µ—Ç–æ–¥–∏–∫–∏ –∏–ª–∏ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã, –∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∑–Ω–∞–µ—Ç. –ù–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –ø–∏—Å–∞—Ç—å –¥–∞–ª—å—à–µ –≤ —á–∞—Ç, —É—Ç–æ—á–Ω—è—è –≤—Å–µ –º–æ–º–µ–Ω—Ç—ã –∏ –Ω–µ —Ç–æ–ª—å–∫–æ –ø–æ –µ–≥–æ –∞–Ω–∞–ª–∏–∑—É. –£ —Ç–µ–±—è –µ—Å—Ç—å –±–æ–ª—å—à–∞—è –ª—É–∫—Å–º–∞–∫—Å –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö, –ø–æ —ç—Ç–æ–º—É —Ç—ã –º–æ–∂–µ—à—å —É—Ç–æ—á–Ω–∏—Ç—å –≤—Å–µ –º–æ–º–µ–Ω—Ç—ã.

---
–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ñ–æ—Ä–º–∞—Ç—É:
‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ Markdown-–∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Å–ø–∏—Å–∫–∏, –±–µ–∑ —Ç–∞–±–ª–∏—Ü.
‚Ä¢ –ù–µ –≤—ã–≤–æ–¥–∏ N/A –∏–ª–∏ "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö" ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–π.
‚Ä¢ –°–æ–±–ª—é–¥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π, —Å–ª–µ–≥–∫–∞ –ø–∞—Ñ–æ—Å–Ω—ã–π —Ç–æ–Ω —Å–æ–≥–ª–∞—Å–Ω–æ system_prompt.
‚Ä¢ –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∂–∏—Ä–Ω—ã–π/–∫—É—Ä—Å–∏–≤ (`**`, `*`, `_`).

```json
{metrics_json}
```


–î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ—Ç–¥–µ–ª–∞ (¬´–ö–æ—Å—Ç–Ω—ã–π –∫–∞—Ä–∫–∞—Å¬ª, ¬´–ì–ª–∞–∑–Ω–∞—è –∑–æ–Ω–∞¬ª, ¬´–ö–æ–∂–∞¬ª, ¬´–ù–æ—Å¬ª, ¬´–ß–µ–ª—é—Å—Ç—å¬ª –∏ —Ç.–¥.):
‚Ä¢ –ü—Ä–∏–≤–µ–¥–∏ –∫–ª—é—á–µ–≤—ã–µ —Ü–∏—Ñ—Ä—ã –∏–∑ –º–µ—Ç—Ä–∏–∫.
‚Ä¢ –ö—Ä–∞—Ç–∫–æ –ø–æ—è—Å–Ω–∏, –ø–æ—á–µ–º—É —ç—Ç–æ –ø–ª—é—Å/–º–∏–Ω—É—Å –¥–ª—è –≤–Ω–µ—à–Ω–æ—Å—Ç–∏ (–∏—Å–ø–æ–ª—å–∑—É–π lookmax-—Å–ª–µ–Ω–≥, –Ω–æ –±–µ–∑ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–π).

## 4. –ß–ï–°–¢–ù–´–ô –í–ï–†–î–ò–ö–¢
–°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã ‚Äî 3-4 –ø—É–Ω–∫—Ç–∞.
–°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã ‚Äî 3-4 –ø—É–Ω–∫—Ç–∞.

## 5. –ü–õ–ê–ù –£–õ–£–ß–®–ï–ù–ò–ô
–°—Ñ–æ—Ä–º–∏—Ä—É–π –¥–æ—Ä–æ–∂–Ω—É—é –∫–∞—Ä—Ç—É:
‚Ä¢ 0-30 –¥–Ω–µ–π
‚Ä¢ 1-6 –º–µ—Å—è—Ü–µ–≤
‚Ä¢ 6-12 –º–µ—Å—è—Ü–µ–≤
–î–ª—è –∫–∞–∂–¥–æ–π —Ü–µ–ª–∏ —É–∫–∞–∂–∏ KPI –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (–ø—Ä–æ—Ü–µ–¥—É—Ä—ã, —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏, –ø—Ä–∏–≤—ã—á–∫–∏).

## 6. –¢–û–ß–ï–ß–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
–î–∞–π –º–∏–Ω–∏–º—É–º 8 –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–æ–≤–µ—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ ¬´–¥–µ–π—Å—Ç–≤–∏–µ ‚Üí –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç¬ª.



    
"""
    user_prompt = user_prompt_template.format(metrics_json=metrics_json_str, lookism_knowledge=LOOKSMAXING_KNOWLEDGE, **template_data)

    try:
        logger.info("Sending request to DeepSeek API with the new, detailed prompt...")
        chat_completion = await client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.4,
            max_tokens=2048
        )
        report = chat_completion.choices[0].message.content
        logger.info("Report generated successfully by DeepSeekAI.")
        return report
    except Exception as e:
        logger.error(f"Failed to generate report from DeepSeekAI: {e}", exc_info=True)
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —á–∏—Å–ª–æ–≤—ã–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è–º."


async def process_task(task_data: dict):
    """Process a single analysis task from the queue."""
    user_id = task_data['user_id']
    chat_id = task_data['chat_id']
    front_photo_id = task_data['front_photo_id']
    profile_photo_id = task_data.get('profile_photo_id') # Profile photo is optional

    logger.info(f"Processing task for user {user_id} in chat {chat_id}")

    try:
        # --- Download and validate photos ---
        front_photo_bytes = await download_photo(front_photo_id)
        if not front_photo_bytes or not is_bright_enough(front_photo_bytes):
            await send_telegram_message(chat_id, "–§–æ—Ç–æ –∞–Ω—Ñ–∞—Å –Ω–µ –ø—Ä–æ—à–ª–æ –ø—Ä–æ–≤–µ—Ä–∫—É (—Å–ª–∏—à–∫–æ–º —Ç–µ–º–Ω–æ–µ –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å). –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
            return

        profile_photo_bytes = None
        if profile_photo_id:
            profile_photo_bytes = await download_photo(profile_photo_id)

        

        # --- Face++ API Calls ---
        front_face_data = await detect_face(front_photo_bytes)
        if "error_message" in front_face_data or not front_face_data.get('faces'):
            error_msg = front_face_data.get("error_message", "–õ–∏—Ü–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            await send_telegram_message(chat_id, f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ç–æ –∞–Ω—Ñ–∞—Å: {error_msg}.\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —Å –±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º.")
            return

        profile_face_data = None
        if profile_photo_bytes:
            profile_face_data = await detect_face(profile_photo_bytes)
            if "error_message" in profile_face_data or not profile_face_data.get('faces'):
                logger.warning(f"Could not detect face in profile photo for user {user_id}. Proceeding without it.")
                profile_face_data = None # Reset if analysis failed

        # --- Compute Metrics ---
        # We use the first detected face
        front_data = front_face_data['faces'][0]
        profile_data = profile_face_data['faces'][0] if profile_face_data and profile_face_data.get('faces') else None

        all_metrics = compute_all(front_data, profile_data)

        skin_score = all_metrics.get('skin_score', 'N/A')
        

        # --- Generate and Send Report ---
        # --- Save metrics to user profile ---
        await save_user_metrics(user_id, all_metrics)
        logger.info(f"Saved analysis metrics for user {user_id} to their profile.")

        # --- Generate and Send Report ---
        report_text = await generate_report(all_metrics)
        # –û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ LLM –æ—Ç markdown-–±–ª–æ–∫–æ–≤
        if report_text.startswith('```markdown'):
            report_text = report_text[len('```markdown'):].strip()
        if report_text.endswith('```'):
            report_text = report_text[:-len('```')].strip()
        
        # Remove any bold/italic markdown emphasis to avoid Telegram parse errors
        def _strip_emphasis(text: str) -> str:
            """Remove bold/italic markdown markers (**, __, *, _) from text while keeping content."""
            # First replace bold (** or __)
            text = re.sub(r"(\*\*|__)(.*?)\1", r"\2", text)
            # Then replace italics (* or _) but avoid bullets like "- *" (we don't use such bullets)
            text = re.sub(r"(\*|_)(.*?)\1", r"\2", text)
            return text

        def _fix_rating_scale(text: str) -> str:
            """Detect ratings formatted like '(XX/10)' where XX>10 and scale down."""
            def _replace(match):
                num = float(match.group(1))
                if num > 10:
                    num /= 10
                num = round(num, 1)
                return f"({num}/10)"
            # Pattern: (number/10) where number may be >10
            return re.sub(r"\((\d+(?:\.\d+)?)/10\)", _replace, text)

        clean_report = _fix_rating_scale(_strip_emphasis(report_text))

        for part in split_long_message(clean_report):
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–µ–∑ parse_mode, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Markdown
            await send_telegram_message(chat_id, part, parse_mode=None)

        await decrement_user_analyses(user_id)
        logger.info(f"Successfully processed task and sent report to user {user_id}")

    except Exception as e:
        logger.error(f"Unhandled error in process_task for user {user_id}: {e}", exc_info=True)
        await send_telegram_message(chat_id, "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞. –ú—ã —É–∂–µ —Ä–∞–∑–±–∏—Ä–∞–µ–º—Å—è.")


async def main():
    """Main worker entry point."""
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    await create_db_and_tables()
    
    redis_client = redis.from_url(os.getenv("REDIS_URL", "redis://localhost"))
    logger.info("Worker started, listening for tasks in 'analysis_queue'...")
    
    try:
        while True:
            # BRPOP is a blocking call that waits for a task
            _, task_json = await redis_client.brpop('analysis_queue')
            if task_json:
                task_data = json.loads(task_json)
                logger.info(f"Dequeued task: {task_data}")
                await process_task(task_data)
    except asyncio.CancelledError:
        logger.info("Worker shutting down.")
    except Exception as e:
        logger.error(f"An error occurred in the main worker loop: {e}", exc_info=True)
    finally:
        await redis_client.close()


if __name__ == "__main__":
    asyncio.run(main())
