"""Background worker for processing facial analysis tasks."""

import asyncio
import logging
import os
import time
from datetime import datetime
from typing import Optional
from sqlalchemy.ext.asyncio import AsyncSession

from database import get_session, create_db_and_tables
from models import Session, Task, SessionStatus, TaskStatus
from task_queue import task_queue
from analyzers.client import FacePlusPlusClient, AILabClient, DeepSeekClient
from analyzers.metrics import extract_all_metrics
from analyzers.lookism_metrics import compute_all as compute_geo_metrics
from analyzers.report_generator import generate_full_report, generate_system_prompt_with_knowledge
import httpx

logger = logging.getLogger(__name__)

# Knowledge base for recommendations
KNOWLEDGE_BASE = """
Ð£ÐŸÐ ÐÐ–ÐÐ•ÐÐ˜Ð¯ Ð˜ ÐŸÐ ÐžÐ¦Ð•Ð”Ð£Ð Ð«:
- ÐœÑŒÑŽÐ¸Ð½Ð³ (mewing) - Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð°Ñ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ñ ÑÐ·Ñ‹ÐºÐ° Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ñ‡ÐµÐ»ÑŽÑÑ‚Ð¸
- Ð–ÐµÐ²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑƒÐ¿Ñ€Ð°Ð¶Ð½ÐµÐ½Ð¸Ñ Ñ Ð¶Ð²Ð°Ñ‡ÐºÐ¾Ð¹ Falim Ð´Ð»Ñ Ñ€Ð°Ð·Ð²Ð¸Ñ‚Ð¸Ñ Ð¼Ð°ÑÑÐµÑ‚ÐµÑ€Ð¾Ð²
- Ð£Ð¿Ñ€Ð°Ð¶Ð½ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð³Ð»Ð°Ð· Ð¸ ÐºÐ°Ð½Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚Ð¸Ð»Ñ‚Ð°
- Ð¡ÐºÑ€Ð°Ð±Ð¸Ð½Ð³ Ð¸ ÑƒÑ…Ð¾Ð´ Ð·Ð° ÐºÐ¾Ð¶ÐµÐ¹ Ð»Ð¸Ñ†Ð°
- ÐœÐ°ÑÑÐ°Ð¶ Ð»Ð¸Ñ†Ð° Ð´Ð»Ñ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ ÐºÑ€Ð¾Ð²Ð¾Ð¾Ð±Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ñ

Ð”ÐžÐ‘ÐÐ’ÐšÐ˜:
- ÐšÐ¾Ð»Ð»Ð°Ð³ÐµÐ½ Ð´Ð»Ñ ÑƒÐ¿Ñ€ÑƒÐ³Ð¾ÑÑ‚Ð¸ ÐºÐ¾Ð¶Ð¸
- Ð’Ð¸Ñ‚Ð°Ð¼Ð¸Ð½ D3 + K2 Ð´Ð»Ñ ÐºÐ¾ÑÑ‚Ð½Ð¾Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹
- Ð¦Ð¸Ð½Ðº Ð´Ð»Ñ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÑ ÐºÐ¾Ð¶Ð¸
- ÐžÐ¼ÐµÐ³Ð°-3 Ð´Ð»Ñ Ð¿Ñ€Ð¾Ñ‚Ð¸Ð²Ð¾Ð²Ð¾ÑÐ¿Ð°Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ ÑÑ„Ñ„ÐµÐºÑ‚Ð°

ÐŸÐ ÐžÐ¦Ð•Ð”Ð£Ð Ð«:
- Ð¤Ð¸Ð»Ð»ÐµÑ€Ñ‹ Ð´Ð»Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ†Ð¸Ð¸ Ð¾Ð±ÑŠÐµÐ¼Ð°
- Ð‘Ð¾Ñ‚Ð¾ÐºÑ Ð´Ð»Ñ Ñ€Ð°Ð·Ð³Ð»Ð°Ð¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ð¼Ð¾Ñ€Ñ‰Ð¸Ð½
- Ð Ð¸Ð½Ð¾Ð¿Ð»Ð°ÑÑ‚Ð¸ÐºÐ° Ð´Ð»Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ†Ð¸Ð¸ Ð½Ð¾ÑÐ°
- Ð‘Ð»ÐµÑ„Ð°Ñ€Ð¾Ð¿Ð»Ð°ÑÑ‚Ð¸ÐºÐ° Ð´Ð»Ñ Ð²ÐµÐº
- ÐŸÐ¾Ð´Ñ‚ÑÐ¶ÐºÐ° Ð»Ð¸Ñ†Ð°
"""

SYSTEM_PROMPT = f"""Ð¢Ñ‹ â€” Ñ€ÑƒÑÑÐºÐ¾ÑÐ·Ñ‹Ñ‡Ð½Ñ‹Ð¹ looksmax-ÐºÐ¾ÑƒÑ‡. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð»Ñ‘Ð³ÐºÐ¸Ð¹ Ð»ÑƒÐºÑÐ¼Ð°ÐºÑ ÑÐ»ÐµÐ½Ð³ (HTN, Chad-Lite, Sub-5 Ð¸ Ñ‚.Ð´.), Ð½Ð¾ Ð±ÐµÐ· Ð¾ÑÐºÐ¾Ñ€Ð±Ð»ÐµÐ½Ð¸Ð¹.
Ð”Ð°Ð¹ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:

ðŸ·ï¸ Ð Ð•Ð™Ð¢Ð˜ÐÐ“ Ð˜ ÐšÐÐ¢Ð•Ð“ÐžÐ Ð˜Ð¯  
Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³: {{base_rating}}/10 | ÐšÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð½Ñ‹Ð¹: {{composite_rating}}/10 | ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ: {{category}}

### ðŸ“Š Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ«Ð™ ÐÐÐÐ›Ð˜Ð— ÐœÐ•Ð¢Ð Ð˜Ðš  
â€¢ ÐšÐ°Ð½Ñ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ‚Ð¸Ð»Ñ‚: {{canthal_tilt}}Â° (Ð¾Ð¿Ñ‚Ð¸Ð¼ÑƒÐ¼: +2-5Â°)
â€¢ Ð“Ð¾Ð½Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑƒÐ³Ð¾Ð»: {{gonial_angle}}Â° (Ð¾Ð¿Ñ‚Ð¸Ð¼ÑƒÐ¼: 120Â°)
â€¢ ÐŸÑ€Ð¾Ð¿Ð¾Ñ€Ñ†Ð¸Ð¸ Ð»Ð¸Ñ†Ð°: {{facial_thirds}}
â€¢ Ð¡Ð¸Ð¼Ð¼ÐµÑ‚Ñ€Ð¸Ñ: {{symmetry_score}}/10
â€¢ ÐŸÑ€Ð¾ÐµÐºÑ†Ð¸Ñ Ð¿Ð¾Ð´Ð±Ð¾Ñ€Ð¾Ð´ÐºÐ°: {{chin_projection}}

### ðŸ’¬ Ð§Ð•Ð¡Ð¢ÐÐÐ¯ ÐžÐ¦Ð•ÐÐšÐ  
2-4 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ Ð¾ ÑÐ¸Ð»ÑŒÐ½Ñ‹Ñ… Ð¸ ÑÐ»Ð°Ð±Ñ‹Ñ… ÑÑ‚Ð¾Ñ€Ð¾Ð½Ð°Ñ… Ð²Ð½ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸.

### ðŸ“Œ Ð”Ð•Ð¢ÐÐ›Ð¬ÐÐ«Ð™ ÐŸÐ›ÐÐ Ð£Ð›Ð£Ð§Ð¨Ð•ÐÐ˜Ð™  
**ÐÐµÐ¼ÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ðµ (0-3 Ð¼ÐµÑÑÑ†Ð°):**
- ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ ÑƒÐ¿Ñ€Ð°Ð¶Ð½ÐµÐ½Ð¸Ñ Ð¸ Ð¿Ñ€Ð¾Ñ†ÐµÐ´ÑƒÑ€Ñ‹

**Ð¡Ñ€ÐµÐ´Ð½ÐµÑÑ€Ð¾Ñ‡Ð½Ñ‹Ðµ (3-12 Ð¼ÐµÑÑÑ†ÐµÐ²):**
- Ð‘Ð¾Ð»ÐµÐµ ÑÐµÑ€ÑŒÑ‘Ð·Ð½Ñ‹Ðµ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ

**Ð”Ð¾Ð»Ð³Ð¾ÑÑ€Ð¾Ñ‡Ð½Ñ‹Ðµ (1+ Ð³Ð¾Ð´):**
- ÐšÐ°Ñ€Ð´Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ

### ðŸ” ÐšÐžÐÐšÐ Ð•Ð¢ÐÐ«Ð• ÐŸÐ ÐžÐ”Ð£ÐšÐ¢Ð«  
Ð’Ñ‹Ð´Ð°Ð¹ 3-5 Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¹ Ð¸Ð· KNOWLEDGE_BASE, Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ñ… Ð¿Ð¾Ð´ ÑÐ»Ð°Ð±Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸.

ðŸ’¬ Ð¢ÐµÐ¿ÐµÑ€ÑŒ Ð¼Ð¾Ð¶ÐµÑˆÑŒ Ð·Ð°Ð´Ð°Ð²Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹!

KNOWLEDGE_BASE = \"\"\"{KNOWLEDGE_BASE}\"\"\"
"""


class AnalysisWorker:
    """Background worker for facial analysis processing."""
    
    def __init__(self):
        self.facepp_client = FacePlusPlusClient()
        self.ailab_client = AILabClient()
        self.deepseek_client = DeepSeekClient()
        self.running = False
    
    async def download_photo(self, file_id: str, bot_token: str) -> bytes:
        """Download photo from Telegram servers."""
        async with httpx.AsyncClient() as client:
            # Get file path
            file_response = await client.get(
                f"https://api.telegram.org/bot{bot_token}/getFile?file_id={file_id}"
            )
            file_data = file_response.json()
            
            if not file_data.get("ok"):
                raise Exception(f"Failed to get file info: {file_data}")
            
            file_path = file_data["result"]["file_path"]
            
            # Download file
            download_response = await client.get(
                f"https://api.telegram.org/file/bot{bot_token}/{file_path}"
            )
            download_response.raise_for_status()
            
            return download_response.content
    
    async def process_session(self, session_id: int) -> None:
        """Process a single analysis session."""
        async for db_session in get_session():
            try:
                # Get session from database
                session = await db_session.get(Session, session_id)
                if not session:
                    logger.error(f"Session {session_id} not found")
                    return
                
                # Update session status
                session.status = SessionStatus.PROCESSING
                await db_session.commit()
                
                # Create task record
                task = Task(session_id=session_id, status=TaskStatus.PROCESSING, started_at=datetime.utcnow())
                db_session.add(task)
                await db_session.commit()
                
                logger.info(f"Processing session {session_id}")
                
                # Download photos
                bot_token = os.getenv("BOT_TOKEN")
                front_photo = await self.download_photo(session.front_file_id, bot_token)
                profile_photo = await self.download_photo(session.profile_file_id, bot_token)
                
                # Analyze with Face++
                logger.info("Analyzing with Face++...")
                facepp_result = await self.facepp_client.analyze_face(front_photo)
                
                # Analyze with AILab
                logger.info("Analyzing with AILab...")
                ailab_result = await self.ailab_client.analyze_face(front_photo)
                
                # Extract metrics (beauty + 106-landmark metrics)
                logger.info("Extracting metrics...")
                metrics = extract_all_metrics(facepp_result, ailab_result)

                # Extra geometric metrics from 83-point Face++ landmarks
                try:
                    face_landmarks = facepp_result["faces"][0].get("landmark", {})
                    if face_landmarks:
                        geo_metrics = compute_geo_metrics(face_landmarks)
                        metrics.update(geo_metrics)
                except Exception as geo_err:
                    logger.warning(f"Failed to compute geo metrics: {geo_err}")
                
                # Generate report with DeepSeek or fallback to template
                logger.info("Generating report...")
                try:
                    # Try DeepSeek API first
                    system_prompt = generate_system_prompt_with_knowledge()
                    report_text = await self.deepseek_client.generate_report(
                        metrics, system_prompt
                    )
                except Exception as deepseek_err:
                    logger.warning(f"DeepSeek failed, using template: {deepseek_err}")
                    # Fallback to template-based report
                    report_text = generate_full_report(metrics)
                
                # Save results
                session.result_json = {
                    "metrics": metrics,
                    "report": report_text,
                    "facepp_raw": facepp_result,
                    "ailab_raw": ailab_result
                }
                session.status = SessionStatus.DONE
                session.finished_at = datetime.utcnow()
                
                task.status = TaskStatus.DONE
                task.finished_at = datetime.utcnow()
                
                await db_session.commit()
                
                logger.info(f"Successfully processed session {session_id}")
                
            except Exception as e:
                logger.error(f"Error processing session {session_id}: {e}")
                
                # Mark as failed
                if 'session' in locals():
                    session.status = SessionStatus.FAILED
                    await db_session.commit()
                
                if 'task' in locals():
                    task.status = TaskStatus.FAILED
                    task.error_message = str(e)
                    task.finished_at = datetime.utcnow()
                    await db_session.commit()
    
    async def run(self) -> None:
        """Main worker loop."""
        logger.info("Starting analysis worker...")
        self.running = True
        
        while self.running:
            try:
                # Get next task from queue
                task_data = await task_queue.dequeue(timeout=5)
                
                if task_data:
                    session_id = task_data["session_id"]
                    await self.process_session(session_id)
                
            except Exception as e:
                logger.error(f"Worker error: {e}")
                await asyncio.sleep(1)
    
    def stop(self) -> None:
        """Stop the worker."""
        logger.info("Stopping analysis worker...")
        self.running = False


async def main():
    """Main worker entry point."""
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    # Setup logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Initialize database
    await create_db_and_tables()
    
    # Initialize queue
    await task_queue.connect()
    
    # Start worker
    worker = AnalysisWorker()
    
    try:
        await worker.run()
    except KeyboardInterrupt:
        logger.info("Worker interrupted by user")
    finally:
        worker.stop()
        await task_queue.disconnect()


if __name__ == "__main__":
    asyncio.run(main())
